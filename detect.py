# YOLOv5 ğŸš€ by Ultralytics, GPL-3.0 license
"""
Run inference on images, videos, directories, streams, etc.

Usage:
    $ python path/to/detect.py --source path/to/img.jpg --weights yolov5s.pt --img 640
"""
import argparse
import math
import os
import sys
import threading
import time
from pathlib import Path
import cv2
import numpy as np
import torch
from ultralytics.utils.ops import scale_coords
from ultralytics.utils.plotting import Annotator
from models.common import DetectMultiBackend
from utils.augmentations import letterbox
from utils.general import set_logging, xyxy2xywh, print_args, non_max_suppression,scale_boxes
from SendInput import *
import pynput
from pynput.mouse import Listener
from screen import screenshot

# å®šä¹‰æ–‡ä»¶è·¯å¾„å’Œæ ¹ç›®å½•
FILE = Path(__file__).resolve()
ROOT = FILE.parents[0]  # YOLOv5 æ ¹ç›®å½•
if str(ROOT) not in sys.path:
    sys.path.append(str(ROOT))  # å°† ROOT æ·»åŠ åˆ°ç³»ç»Ÿè·¯å¾„
ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # è½¬ä¸ºç›¸å¯¹è·¯å¾„

# å®šä¹‰ä¸€ä¸ªå…¨å±€å˜é‡ï¼Œè¡¨ç¤ºè‡ªç„æ˜¯å¦å¯ç”¨
is_useful = False
# é¼ æ ‡ç‚¹å‡»äº‹ä»¶çš„å›è°ƒå‡½æ•°
def mouse_click(x, y, button, pressed):
    """
    æŒ‰ä¸‹ä¾§é”® X2 æ—¶å¯ç”¨è‡ªç„ï¼Œé‡Šæ”¾ä¾§é”® X2 æ—¶å…³é—­è‡ªç„ã€‚
    """
    global is_useful
    if pressed and button == pynput.mouse.Button.x2:  # æ£€æµ‹æ˜¯å¦æŒ‰ä¸‹é¼ æ ‡ä¾§é”® X2
        is_useful = True  # å¯ç”¨è‡ªç„
    elif not pressed and button == pynput.mouse.Button.x2:  # æ£€æµ‹æ˜¯å¦é‡Šæ”¾é¼ æ ‡ä¾§é”® X2
        is_useful = False  # ç¦ç”¨è‡ªç„
# é¼ æ ‡ç›‘å¬å™¨
def mouse_listenr():
    """
    ç›‘å¬é¼ æ ‡ç‚¹å‡»äº‹ä»¶ï¼Œç”¨äºåˆ‡æ¢è‡ªç„çŠ¶æ€ã€‚
    """
    with Listener(on_click=mouse_click) as listener:
        listener.join()

# YOLOv5 æ¨ç†ä¸»ç¨‹åº
@torch.no_grad()
def run():
    """
    å¯åŠ¨è‡ªç„é€»è¾‘ï¼ŒåŒ…æ‹¬ç›®æ ‡æ£€æµ‹å’Œé¼ æ ‡ç§»åŠ¨æ¨¡æ‹Ÿã€‚
    """
    # åˆå§‹åŒ–è®¾å¤‡å’Œæ¨¡å‹
    device = torch.device('cuda:0')  # ä½¿ç”¨ GPU è¿›è¡ŒåŠ é€Ÿ
    model = DetectMultiBackend(
        weights='runs/train/exp/weights/best.pt',  # æ¨¡å‹æƒé‡è·¯å¾„
        device=device,  # æ¨ç†è®¾å¤‡
        dnn=False,
        data=False,
        fp16=True  # å¯ç”¨ FP16 åŠ é€Ÿ
    )

    while True:
        # æˆªå–å½“å‰å±å¹•
        img = screenshot()
        im0 = img.copy()  # ä¿ç•™åŸå§‹æˆªå›¾

        # å¯¹æˆªå›¾è¿›è¡Œé¢„å¤„ç†
        img = letterbox(img, (640, 640), stride=32, auto=True)[0]  # è°ƒæ•´ä¸ºç¬¦åˆæ¨¡å‹è¾“å…¥çš„å¤§å°
        img = img.transpose((2, 0, 1))[::-1]  # HWC è½¬ CHWï¼ŒBGR è½¬ RGB
        img = np.ascontiguousarray(img)

        img = torch.from_numpy(img).to(model.device)  # è½¬ä¸º Tensor å¹¶å‘é€åˆ°è®¾å¤‡
        img = img.half() if model.fp16 else img.float()  # è½¬ä¸º float16 æˆ– float32
        img /= 255.0  # å½’ä¸€åŒ–

        if len(img.shape) == 3:
            img = img[None]  # æ‰©å±•ä¸º batch ç»´åº¦

        # æ¨¡å‹æ¨ç†
        pred = model(img, augment=False, visualize=False)
        pred = non_max_suppression(
            pred, conf_thres=0.6, iou_thres=0.45, classes=0, max_det=1000
        )

        # å¤„ç†æ£€æµ‹ç»“æœ
        for i, det in enumerate(pred):  # éå†æ¯å¼ å›¾ç‰‡çš„æ£€æµ‹ç»“æœ
            annotator = Annotator(im0, line_width=1)  # åˆå§‹åŒ–æ³¨é‡Šå™¨
            if len(det):  # å¦‚æœæœ‰æ£€æµ‹åˆ°ç›®æ ‡
                distance_list = []
                target_list = []

                # å°†æ£€æµ‹æ¡†ä»æ¨¡å‹å°ºå¯¸æ˜ å°„åˆ°åŸå§‹å›¾ç‰‡å°ºå¯¸
                det[:, :4] = scale_boxes(img.shape[2:], det[:, :4], im0.shape).round()
                for *xyxy, conf, cls in reversed(det):
                    xywh = (
                        xyxy2xywh(torch.tensor(xyxy).view(1, 4))
                    ).view(-1).tolist()  # è½¬ä¸ºä¸­å¿ƒç‚¹åæ ‡å’Œå®½é«˜
                    #X,Yè¡¨ç¤ºç›¸å¯¹æˆªå›¾æ¡†åŸç‚¹ï¼ˆå·¦ä¸Šè§’ï¼‰çš„è·ç¦» X1,Y1è¡¨ç¤ºç›¸å¯¹äºæˆªå›¾æ¡†ä¸­å¿ƒï¼ˆæ¸¸æˆå‡†æ˜Ÿï¼‰çš„XYæ–¹å‘è·ç¦»
                    # X = xywh[0]
                    # Y = xywh[1]
                    X1 = xywh[0] - 200
                    Y1 = xywh[1] - 200
                    #print(X,Y,X1,Y1) æ‰“å°åæ ‡ç”¨äºè§‚å¯Ÿ
                    distance = math.sqrt(X1**2 + Y1**2)  # è®¡ç®—è·ç¦»
                    xywh.append(distance)
                    # ç»˜åˆ¶æ£€æµ‹æ¡†
                    annotator.box_label(
                        xyxy, label=f'[{int(cls)}]', color=(255, 0, 0), txt_color=(255, 255, 255)
                    )
                    distance_list.append(distance)  # è·ç¦»åˆ—è¡¨
                    target_list.append(xywh)  # ç›®æ ‡ä¿¡æ¯åˆ—è¡¨
                # è·å–æœ€è¿‘çš„ç›®æ ‡ä¿¡æ¯
                target_info = target_list[distance_list.index(min(distance_list))]
                if is_useful:  # å¦‚æœè‡ªç„å¯ç”¨
                    mouse_xy(int(target_info[0] - 200), int(target_info[1] - 200))  # ç§»åŠ¨é¼ æ ‡
                    time.sleep(0.0025)
            # æ˜¾ç¤ºç»“æœ
            im0 = annotator.result()
            cv2.imshow('test', im0)
            cv2.setWindowProperty('test', cv2.WND_PROP_TOPMOST, 1)
            cv2.waitKey(1)

if __name__ == "__main__":
    # ä½¿ç”¨å¤šçº¿ç¨‹å¯åŠ¨é¼ æ ‡ç›‘å¬å™¨
    threading.Thread(target=mouse_listenr).start()
    run()